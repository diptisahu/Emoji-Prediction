{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diptisahu/Emoji-Prediction/blob/main/Lstm-GloVe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0SjS9_VR_aCT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-jY8k6YQm2jr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a98585fe-ca19-459f-bc12-f108ab8154a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-16 00:33:06--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-03-16 00:33:06--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-03-16 00:33:06--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.07MB/s    in 2m 40s  \n",
            "\n",
            "2022-03-16 00:35:46 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GR4B3z3m6mG",
        "outputId": "859bc978-0466-4eb3-cebb-8b9140c9000e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip glove*.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GYtRxi9mqTh",
        "outputId": "0e9cda6d-4b31-43ef-f9f6-84f3e06adbed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "glove_dir = './glove.6B.200d.txt'\n",
        "input_dim = 200\n",
        "\n",
        "vocab = {}\n",
        "with open(glove_dir, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        vocab[word] = vector\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' %len(vocab))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k5DAodr8mqTi"
      },
      "outputs": [],
      "source": [
        "max_len = 50\n",
        "zero_padding = [0]*input_dim\n",
        "\n",
        "def get_embeddings(text, emb=\"LSTM\"):\n",
        "    if emb == \"DNN\":\n",
        "        embedding = [0]*input_dim\n",
        "        i = 0\n",
        "        for word in text.split(' '):\n",
        "            if word in vocab:\n",
        "                i += 1\n",
        "                embedding += vocab[word]\n",
        "\n",
        "        if i != 0:\n",
        "            embedding /= i\n",
        "    elif emb == \"LSTM\":\n",
        "        embedding = []\n",
        "        i = 0\n",
        "        for word in text.split(' '):\n",
        "            if i == max_len:\n",
        "                break\n",
        "            if word in vocab:\n",
        "                i += 1\n",
        "                scale = 0.1\n",
        "                noise = np.random.randn(input_dim)*scale\n",
        "                embedding.append(vocab[word] + noise)\n",
        "        \n",
        "        while i < max_len:\n",
        "            i += 1\n",
        "            embedding.append(zero_padding)\n",
        "            \n",
        "    return embedding"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8VpbL9SuIaGb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "XGqwjUYjmqTj"
      },
      "outputs": [],
      "source": [
        "def clean(text):\n",
        "    \"\"\" Function to clean the text \"\"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
        "    texter = re.sub(r\"<br />\", \" \", text)\n",
        "    texter = re.sub(r\"&quot;\", \"\\\"\",texter)\n",
        "    texter = re.sub('&#39;', \"\\\"\", texter)\n",
        "    texter = re.sub('\\n', \" \", texter)\n",
        "    texter = re.sub(' u ',\" you \", texter)\n",
        "    texter = re.sub('`',\"\", texter)\n",
        "    texter = re.sub(' +', ' ', texter)\n",
        "    texter = re.sub(r\"(!)\\1+\", r\"!\", texter)\n",
        "    texter = re.sub(r\"(\\?)\\1+\", r\"?\", texter)\n",
        "    texter = re.sub('&amp;', 'and', texter)\n",
        "    texter = re.sub('\\r', ' ',texter)\n",
        "    \n",
        "    # Remove numbers from string\n",
        "    texter = re.sub(pattern=r\"[+-]?\\d+(?:\\.\\d+)?\", repl=\"\", string=texter, count=0, flags=0)\n",
        "    texter = texter.replace(\"  \", \" \")\n",
        "    clean = re.compile('<.*?>')\n",
        "    texter = texter.encode('ascii', 'ignore').decode('ascii')\n",
        "    texter = re.sub(clean, '', texter)\n",
        "    texter = re.sub(r'[^\\w\\s]', '', texter)\n",
        "    if texter == \"\":\n",
        "        texter = \"\"\n",
        "    return texter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LMDquilkmqTj"
      },
      "outputs": [],
      "source": [
        "def transform(X, emb=\"LSTM\"):\n",
        "    embeddings = []\n",
        "    for item in X:\n",
        "        item = clean(item)\n",
        "        embedding = get_embeddings(item, emb)\n",
        "        embeddings.append(embedding)\n",
        "    \n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "l6FJqbVqmqTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2966b130-62fc-40d3-f8af-985be50bb8f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "352867\n"
          ]
        }
      ],
      "source": [
        "inputs_file = \"/content/tweets_training.txt\"\n",
        "labels_file = \"/content/tweets_training_labels.txt\"\n",
        "\n",
        "X = []\n",
        "with open(inputs_file, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        X.append(line)\n",
        "f.close()\n",
        "print(len(X))\n",
        "\n",
        "y = []\n",
        "with open(labels_file, encoding='utf8') as f:\n",
        "    for line in f:\n",
        "        y.append(int(line))\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "boAa17OUmqTm"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 3\n",
        "batch_size = 100\n",
        "learning_rate = 0.0005\n",
        "dropout = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IMS8ig7-mqTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1508574f-4aaf-43fb-9e68-91de72282c03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:201.)\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "299936\n",
            "torch.Size([299936, 50, 200])\n"
          ]
        }
      ],
      "source": [
        "## LSTM\n",
        "\n",
        "with torch.no_grad():\n",
        "  torch.cuda.empty_cache()\n",
        "  X = transform(X)\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=42)\n",
        "\n",
        "  X_tr = torch.tensor(X_train, dtype=torch.float).to('cuda')\n",
        "  y_tr = torch.tensor(y_train).to('cuda')\n",
        "  train = TensorDataset(X_tr, y_tr)\n",
        "  trainloader = DataLoader(train, batch_size=batch_size)\n",
        "  torch.cuda.empty_cache()\n",
        "\n",
        "  X_te = torch.tensor(X_test, dtype=torch.float).to('cuda')\n",
        "  y_te = torch.tensor(y_test).to('cuda')\n",
        "  test = TensorDataset(X_te, y_te)\n",
        "  testloader = DataLoader(test, batch_size=batch_size)\n",
        "\n",
        "  print(len(y_tr))\n",
        "  print(X_tr.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sXs8lgrIa09X",
        "outputId": "14c4c777-97c4-472f-fca2-04ce4b054353"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LSTM(\n",
            "  (lstm): LSTM(200, 64, num_layers=3, batch_first=True, dropout=0.5)\n",
            "  (fc1): Linear(in_features=3200, out_features=128, bias=True)\n",
            "  (fc2): Linear(in_features=128, out_features=20, bias=True)\n",
            "  (dropout): Dropout(p=0.5, inplace=False)\n",
            "  (batchnorm1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class LSTM(nn.Module): \n",
        "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length, dropout):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.num_classes = num_classes #number of classes\n",
        "        self.num_layers = num_layers #number of layers\n",
        "        self.input_size = input_size #input size\n",
        "        self.hidden_size = hidden_size #hidden state\n",
        "        self.seq_length = seq_length #sequence length\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, dropout=dropout, batch_first=True).to('cuda') #lstm\n",
        "        self.fc1 =  nn.Linear(hidden_size*seq_length, 128) #fully connected 1\n",
        "        self.fc2 = nn.Linear(128, num_classes) #fully connected last layer\n",
        "        \n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.batchnorm1 = nn.BatchNorm1d(128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to('cuda') #hidden state\n",
        "        c_0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to('cuda')\n",
        "        \n",
        "        # Propagate input through LSTM\n",
        "        x, _ = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
        "        \n",
        "        # Flatten lstm output\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        \n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = self.dropout(x)\n",
        "#         x = F.log_softmax(self.fc2(x), dim=1)\n",
        "        x = self.fc2(x)\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "lstm = LSTM(20, 200, 64, 3, 50, dropout).to('cuda')\n",
        "\n",
        "print(lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "bTr04BHsmqTm"
      },
      "outputs": [],
      "source": [
        "# Loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# create your optimizer\n",
        "optimizer = optim.Adam(lstm.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntZUSCEamqTn",
        "outputId": "32ef1660-53ec-4371-e05d-5f7b3ce78816"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/3], Step [250/3000], Loss: 2.5790\n",
            "Epoch [1/3], Step [500/3000], Loss: 2.3972\n",
            "Epoch [1/3], Step [750/3000], Loss: 2.3425\n",
            "Epoch [1/3], Step [1000/3000], Loss: 2.4824\n",
            "Epoch [1/3], Step [1250/3000], Loss: 2.2709\n",
            "Epoch [1/3], Step [1500/3000], Loss: 2.4831\n",
            "Epoch [1/3], Step [1750/3000], Loss: 2.5753\n",
            "Epoch [1/3], Step [2000/3000], Loss: 2.1950\n",
            "Epoch [1/3], Step [2250/3000], Loss: 2.3325\n",
            "Epoch [1/3], Step [2500/3000], Loss: 2.4319\n",
            "Epoch [1/3], Step [2750/3000], Loss: 2.3682\n",
            "Epoch [1/3], Step [3000/3000], Loss: 2.2671\n",
            "Epoch [2/3], Step [250/3000], Loss: 2.3114\n",
            "Epoch [2/3], Step [500/3000], Loss: 2.2829\n",
            "Epoch [2/3], Step [750/3000], Loss: 2.1968\n",
            "Epoch [2/3], Step [1000/3000], Loss: 2.4571\n",
            "Epoch [2/3], Step [1250/3000], Loss: 2.1748\n",
            "Epoch [2/3], Step [1500/3000], Loss: 2.4073\n",
            "Epoch [2/3], Step [1750/3000], Loss: 2.4273\n",
            "Epoch [2/3], Step [2000/3000], Loss: 2.0916\n",
            "Epoch [2/3], Step [2250/3000], Loss: 2.3059\n",
            "Epoch [2/3], Step [2500/3000], Loss: 2.3732\n",
            "Epoch [2/3], Step [2750/3000], Loss: 2.4074\n",
            "Epoch [2/3], Step [3000/3000], Loss: 2.1932\n",
            "Epoch [3/3], Step [250/3000], Loss: 2.3005\n",
            "Epoch [3/3], Step [500/3000], Loss: 2.3074\n",
            "Epoch [3/3], Step [750/3000], Loss: 2.1649\n",
            "Epoch [3/3], Step [1000/3000], Loss: 2.3190\n",
            "Epoch [3/3], Step [1250/3000], Loss: 2.1367\n",
            "Epoch [3/3], Step [1500/3000], Loss: 2.2851\n",
            "Epoch [3/3], Step [1750/3000], Loss: 2.3648\n",
            "Epoch [3/3], Step [2000/3000], Loss: 2.0827\n",
            "Epoch [3/3], Step [2250/3000], Loss: 2.3032\n",
            "Epoch [3/3], Step [2500/3000], Loss: 2.2850\n",
            "Epoch [3/3], Step [2750/3000], Loss: 2.3769\n",
            "Epoch [3/3], Step [3000/3000], Loss: 2.0398\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0\n",
        "    for i, data in enumerate(trainloader):\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to('cuda')\n",
        "        labels= labels.to('cuda')\n",
        "        outputs = lstm(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        if (i+1) % 250 == 0:\n",
        "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
        "                   %(epoch+1, num_epochs, i+1, len(trainloader), loss.data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nn3ona57mqTn",
        "outputId": "097071a8-e8f2-4fb3-a680-023a3f4db945"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model is: 32.16%\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "lstm.eval()\n",
        "total, correct = 0, 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "\n",
        "        outputs = lstm(inputs)\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum()\n",
        "\n",
        "print(f'Accuracy of the model is: {100*correct/total:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "wdGPO8nAmqTn"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Emoji_Prediction_GLOVE.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}